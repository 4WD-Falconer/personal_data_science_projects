{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work In Progress - Extracting phrases around craft beer tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "access_token = ''\n",
    "access_token_secret = ''\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of what the raw text from the tweets looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2014 Fluxus in 2018. Yummmmm\\n\\n#allagashbrewing #instabeer #craftbeer #craftbeerporn #ilovebeer… https://t.co/54hjaaJsVM',\n",
       " 'Registration is OPEN! Announces a Collab with.',\n",
       " 'VolleyBristol \"The #PremierLeague #Football just keeps on coming. Today why not have a #VolleyRoast, a pint of… https://t.co/tEVJI7PP2b',\n",
       " 'The #PremierLeague #Football just keeps on coming. Today why not have a #VolleyRoast, a pint of #craftbeer and watc… https://t.co/lozrHVtNg5',\n",
       " 'RT @BBBrandsUK: With probably the last keg in the UK head over to @taproomse18 to give @phbrew #bountyhunter delicious Coconut Chocolate Ni…',\n",
       " 'The #PremierLeague #Football just keeps on coming. Today why not have a #VolleyRoast, a pint of #craftbeer and watc… https://t.co/va9sf7go9Y',\n",
       " 'RT @TheShabbycats: #acoustic duo #TheShabbycats playing #livemusic @TheGroveHudds #Huddersfield today 4-7pm #HuddersfieldIs #realale #Craft…',\n",
       " 'Check out my latest blog post https://t.co/ovplv4OHIt #tinyrebel @tinyrebelbrewco #craftbeer\\xa0#dogfriendly… https://t.co/4OHtXj3OcQ',\n",
       " 'The ultimate beer e-newspaper Thanks to @TableTopDown @ysbeerequipment @grainsandyeast #beer #craftbeer',\n",
       " 'Planning a day out Today? Pop to @mertonabbeymill for some free great live music from around 3ish on the bandstand… https://t.co/Evm0I0JimA']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searched_tweets = [tweet for tweet in tweepy.Cursor(api.search, q='craftbeer', lang='en').items(10)]\n",
    "orig_tweets = [w.text for w in searched_tweets]\n",
    "orig_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get cleaned up text\n",
    "\n",
    "1. Searches for the tweet query and returns the desired number of results\n",
    "2. Grabs only the text from the tweet\n",
    "3. Makes all the text lowercase\n",
    "4. Removes hyperlinks\n",
    "5. Removes usernames and @ mentions\n",
    "6. Removes hashtags\n",
    "7. Removes punctuation and misc. characters\n",
    "8. Removes extra letters in a word (i.e happpyyyy to happy)\n",
    "9. Removes emojis\n",
    "10. Tokenizes the words\n",
    "11. lemmatization of the words\n",
    "12. Removes single characters\n",
    "13. Removes stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "def get_clean_tweets(query, max_tweets):\n",
    "    searched_tweets = [tweet for tweet in tweepy.Cursor(api.search, q=query, lang='en').items(max_tweets)]\n",
    "    clean_tweets = []   \n",
    "    for tweet in searched_tweets:\n",
    "        tweet_text = tweet.text\n",
    "        lower = tweet_text.lower()\n",
    "        link = re.sub(r'https\\S+', ' ', lower)\n",
    "        un = re.sub(r\"(?:\\@)\\S+\", \"\", link)\n",
    "        hash_tag = re.sub(r\"(?:\\#)\\S+\", \"\", un)\n",
    "        punc = re.sub(r\"[,.:;'~‘\\\"\\#\\@\\|’“”%-?!&$]+\\ *\", ' ', hash_tag)\n",
    "        misc = re.sub('rt|…|amp', ' ', punc)\n",
    "        pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "        reduce_leng = pattern.sub(r\"\\1\\1\", misc)\n",
    "        emoji_pattern = re.compile(\"[\"u\"\\U0001F600-\\U0001F64F\" u\"\\U0001F300-\\U0001F5FF\" u\"\\U0001F680-\\U0001F6FF\" u\"\\U0001F1E0-\\U0001F1FF\"  \n",
    "                           u\"\\U00002702-\\U000027B0\" u\"\\U000024C2-\\U0001F251\" u\"\\U0001F900-\\U0001F999\" \"]+\", flags=re.UNICODE)\n",
    "        emoji = emoji_pattern.sub(r'', reduce_leng)\n",
    "        tokenizer = TweetTokenizer()\n",
    "        tokens = tokenizer.tokenize(emoji)\n",
    "        lem = WordNetLemmatizer()\n",
    "        lemword = [lem.lemmatize(w) for w in tokens]\n",
    "        single_char = [w for w in lemword if len(w) > 1]\n",
    "        stop_words = [w for w in single_char if not w in stopwords.words('english')]\n",
    "        clean_tweets.append(stop_words)\n",
    "    return clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_clean_tweets('craftbeer', 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of the cleaned up text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['result',\n",
       "  'main',\n",
       "  'advantage',\n",
       "  'ibeernetwork',\n",
       "  'flexibility',\n",
       "  'simple',\n",
       "  'screen'],\n",
       " ['criterion'],\n",
       " ['depa',\n",
       "  'ing',\n",
       "  'great',\n",
       "  'little',\n",
       "  'haul',\n",
       "  'local',\n",
       "  'fun',\n",
       "  'imbibing',\n",
       "  'ahead'],\n",
       " ['duo', 'playing', 'today', 'pm'],\n",
       " ['spice', 'week', 'tuesday', 'curry', 'night']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which single words appear the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('beer', 500),\n",
       " ('craft', 155),\n",
       " ('day', 136),\n",
       " ('today', 131),\n",
       " ('ale', 121),\n",
       " ('great', 119),\n",
       " ('brewery', 112),\n",
       " ('ipa', 112),\n",
       " ('time', 101),\n",
       " ('get', 99),\n",
       " ('new', 95),\n",
       " ('one', 86),\n",
       " ('pm', 84),\n",
       " ('come', 82),\n",
       " ('brewing', 81),\n",
       " ('tap', 77),\n",
       " ('good', 63),\n",
       " ('weekend', 62),\n",
       " ('brew', 57),\n",
       " ('saturday', 56)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "flat_list = [item for sublist in data for item in sublist]\n",
    "counter = collections.Counter(flat_list)\n",
    "sorted_words = sorted(counter.items(), key=lambda x:x[1], reverse=True)\n",
    "sorted_words[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most common bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('craft', 'beer'), 109),\n",
       " (('po', 'er'), 25),\n",
       " (('pale', 'ale'), 24),\n",
       " (('barrel', 'aged'), 24),\n",
       " (('bourbon', 'barrel'), 23),\n",
       " (('time', 'another'), 21),\n",
       " (('pm', 'pm'), 21),\n",
       " (('beer', 'festival'), 19),\n",
       " (('ex', 'le'), 18),\n",
       " (('enjoying', 'bbq'), 17)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "bigrams = ngrams(flat_list, 2)\n",
    "fdist = nltk.FreqDist(bigrams)\n",
    "sorted_bi = sorted(fdist.items(), key=lambda x:x[1], reverse=True)\n",
    "sorted_bi[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting phrases or words that apear together frequently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Phrases\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "bigram_model = Phrases(data)\n",
    "trigram_model = Phrases(bigram_model[data])\n",
    "trigram_model = list(trigram_model[bigram_model[data]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the 20 most common phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('craft_beer', 76),\n",
       " ('po_er', 25),\n",
       " ('pale_ale', 24),\n",
       " ('enjoying_bbq_friend_home', 17),\n",
       " ('along_sour_favourite_style', 16),\n",
       " ('bourbon_barrel_aged_great', 16),\n",
       " ('ex_le_style', 16),\n",
       " ('pm_pm', 16),\n",
       " ('definitely_time_another_cracker', 14),\n",
       " ('craft_brewery', 13),\n",
       " ('earned_one_best_around', 13),\n",
       " ('brewing_co', 12),\n",
       " ('double_paired', 12),\n",
       " ('perfect_day', 12),\n",
       " ('live_music', 11),\n",
       " ('brewing_company', 11),\n",
       " ('always_soft_spot_glad', 11),\n",
       " ('finally_get_hand_evil', 11),\n",
       " ('craft_beer_festival', 10),\n",
       " ('barrel_room', 10)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "phrase_list = []\n",
    "\n",
    "for item in trigram_model:\n",
    "    for word in item:\n",
    "        if '_' in word:\n",
    "            phrase_list.append(word)\n",
    "\n",
    "counter = collections.Counter(phrase_list)\n",
    "phrase_freq = sorted(counter.items(), key=lambda x:x[1], reverse=True)\n",
    "phrase_freq[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
